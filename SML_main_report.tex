\documentclass{article}


\PassOptionsToPackage{square,comma,numbers,sort&compress}{natbib}

% Keep this line uncomment in the first submission
\usepackage{neurips_2024} 
\usepackage{pdfpages}

%Uncomment this line for the second submission
%\usepackage[final]{neurips_2024}



\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsmath}        % math environments and \text in math mode
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\usepackage{listings}
\lstdefinestyle{mystyle}{
backgroundcolor=\color{backcolour},
commentstyle=\color{codegreen},
keywordstyle=\color{magenta},
numberstyle=\tiny\color{codegray},
stringstyle=\color{codepurple},
basicstyle=\footnotesize\ttfamily,
breakatwhitespace=false,
breaklines=true, captionpos=b,
keepspaces=true, numbers=left,
numbersep=5pt, showspaces=false,
showstringspaces=false,
showtabs=false, tabsize=2,
}
\lstset{style=mystyle}

\bibliographystyle{abbrvnat}

\title{Do we need more bikes?\\
Project in Statistical Machine Learning}

\author{
  Muhammad Aufa Helfiandri\\
}
\makeatletter
\renewcommand{\@noticestring}{}
\makeatother

\begin{document}


\maketitle
\begin{abstract}
In this project, we aim to create a classification model that can predict whether an increase in the number of bikes is needed in Washington D.C. on a specific temporal and meteorogical conditions. We will compare various classification models which consists of Logistic Regression, Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN), Random Forest, and Gradient Boosting. The models are evaluated using Accuracy, Precision, Recall, and F1-Score metrics with 10-Fold Cross Validation. The results indicate that the Random Forest model outperforms the other models in all evaluation metrics, with an accuracy of 94.44\%, recall of 94.99\%, precision of 94.00\%, and F1-score of 94.47\%. This suggests that Random Forest is the most effective model for predicting bike demand in this context.

Number of group member: \textbf{4}
\end{abstract}


\section{Problem Description}
\label{headings}
Capital Bikeshare is a 24-hour public bicycle-sharing system that serves Washington, D.C., and offers transportation for thousands of people throughout the city. The problem that arises is that there are certain occasions when, due to various circumstances, there are not as many bikes available as there are demands. In the long term, this situation will result in more people taking the car instead of the bicycle, increasing CO2 emissions in the city. To tackle this situation, the District Department of Transportation in the city wants to know if at certain hours an increase in the number of bikes available will be necessary.

In this Project, we aim to analyze whether the increase in the number of bikes is necessary or not based on the various temporal and meteorogical data provided in the dataset. 



\section{Data Analysis}
\label{headings}

The Training Dataset training.csv consists of 1600 randomly selected observation over the period of three years in the city of Washington D.C. The dataset contains 16 features and 1 target variable. The features are: \textit{hour\_of\_day}, \textit{day\_of\_week}, \textit{month}, \textit{holiday}, \textit{weekday}, \textit{summertime}, \textit{temp}, \textit{dew}, \textit{humidity}, \textit{precip}, \textit{snow}, \textit{snow\_depth}, \textit{windspeed}, \textit{cloudcover}, and \textit{visibility}. And the target variable is \textit{increase\_stock}.

\subsection{Variable Types and Processing}
\label{headings}

The target variable \textit{increase\_stock} indicates whether an increase in the number of bikes is needed at a particular hour. the value \textit{'low\_bike\_demand'} indicates that no increase is needed, while \textit{'high\_bike\_demand'} indicates that an increase is necessary.  For the analysis, we will convert these categorical values into binary numerical values, where \textit{'low\_bike\_demand'} is represented as 0 and \textit{'high\_bike\_demand'} as 1. Since the target variable is binary, this problem can be treated as a binary classification task.

For Binary features such as \textit{holiday}, \textit{weekday}, and \textit{summertime}, they will be counted as categorical variables with values 0 and 1.

The Features \textit{temp}, \textit{dew}, \textit{humidity}, \textit{precip}, \textit{snow}, \textit{snow\_depth}, \textit{windspeed}, \textit{cloudcover}, and \textit{visibility} will be treated as numerical variables as they represent continuous measurements.

Regarding Ordinal features such as \textit{hour\_of\_day}, \textit{day\_of\_week}, and \textit{month}, special attention is needed. For these features, we can't simply treat them as numerical values due to their cyclical nature. For example, after hour 23 comes hour 0 again. However, treating them as categorical variables may lead to loss of information regarding their order and cyclical patterns. Therefore, there are several possible approaches to handle them:

\begin{itemize}
    \item One-Hot Encoding: Convert each of these features into multiple binary features, each representing a specific category. For example, \textit{hour\_of\_day} would be converted into 24 binary features.
    \item Cyclical Transformation: Transform these features using sine and cosine functions to capture their cyclical nature. For example, for \textit{hour\_of\_day}, we can create two new features: 
    \begin{equation*}
        \text{hour\_sin} = \sin\left(2\pi \cdot \frac{\text{hour\_of\_day}}{24}\right)
        \cite{tds-cyclical-data}
    \end{equation*}
    \begin{equation*}
        \text{hour\_cos} = \cos\left(2\pi \cdot \frac{\text{hour\_of\_day}}{24}\right)
        \cite{tds-cyclical-data}
    \end{equation*}
\end{itemize}

Since One-Hot Encoding wouldn't effectively capture the cyclical nature of these features and may lead to high dimensionality, for this analysis, we will use the Cyclical Transformation approach to handle these ordinal features. \cite{tds-cyclical-data}

After processing, the dataset will consist of 18 features and 1 target variable. Those features are shown in Table~\ref{processed-features-table}.

\begin{table}[!ht]
  \caption{Processed Features in the Dataset}
  \label{processed-features-table}
  \centering
\begin{tabular}{ p{2.5cm} p{3cm} p{6.5cm} }
    \textbf{Feature} & \textbf{Type} & \textbf{Description} \\
    \hline
    hour\_sin & Numerical & Sine transformation of hour of the day \\
    hour\_cos & Numerical & Cosine transformation of hour of the day \\
    day\_sin & Numerical & Sine transformation of day of the week \\
    day\_cos & Numerical & Cosine transformation of day of the week \\
    month\_sin & Numerical & Sine transformation of month of the year \\
    month\_cos & Numerical & Cosine transformation of month of the year \\
    holiday & Binary / Categorical & Whether the day is a holiday or not (0 or 1) \\
    weekday & Binary / Categorical & Whether the day is a weekday or not (0 or 1) \\
    summertime & Binary / Categorical & Whether the day is in the summer time period or not (0 or 1) \\
    temp & Numerical & Temperature in Celsius \\
    dew & Numerical & Dew point temperature in Celsius \\
    humidity & Numerical & Relative Humidity in percentage \\
    precip & Numerical & Precipitation in mm \\
    snow & Numerical & Amount of snow in the last hour in cm \\
    snow\_depth & Numerical & Accumulated snow depth in cm \\
    windspeed & Numerical & Wind speed in km/h \\
    cloudcover & Numerical & Percentage of cloud cover \\
    visibility & Numerical & Distance in km at which objects or landmarks can be clearly seen and identified \\
    increase\_stock (Target) & Binary / Categorical & Whether an increase in bike stock is needed (0 or 1) \\
\end{tabular}
\end{table}


\subsection{Exploratory Data Analysis}
\label{headings}
For the initial stage, we will perform Exploratory Data Analysis (EDA) to understand the distribution and trends that arises in the dataset. Including which features are more correlated with the target variable \textit{increase\_stock}.

The feature \textit{snow} only contains zero values in all observations, therefore it will be removed from the dataset as it doesn't provide any useful information for the analysis. Upon analyzing the dataset, we found that there are no missing values in any of the features or the target variable. Therefore, no handling is required. 

Using Pearson correlation coefficient, we found correlation values between each feature and the target variable as shown in Table~\ref{correlation-table}.

\begin{table}[!ht]
  \caption{Ordered Correlation between Features and Target Variable}
  \label{correlation-table}
  \centering
\begin{tabular}{ p{5cm} p{5cm} }
    \textbf{Feature} & \textbf{Correlation Coefficient} \\
    \hline 
    hour\_of\_day\_cos & -0.339960 \\
    temp & 0.336981 \\
    humidity & -0.308726 \\
    hour\_of\_day\_sin & -0.308121 \\
    summertime & 0.216052 \\
    month\_cos & -0.169059 \\
    dew & 0.132663 \\
    weekday & -0.116446 \\
    visibility & 0.113443 \\
    windspeed & 0.096011 \\
    month\_sin & -0.092078 \\
    day\_of\_week\_sin & -0.088152 \\
    precip & -0.059304 \\
    snowdepth & -0.047526 \\
    cloudcover & -0.045534 \\
    day\_of\_week\_cos & -0.031473 \\
    holiday & -0.004909 \\

\end{tabular}
\end{table}

As the table suggests, the feature \textit{hour\_of\_day\_cos} has the highest positive correlation with the target variable \textit{increase\_stock}, indicating that the time of day plays a significant role in determining whether an increase in bike stock is needed. On the other hand, the feature \textit{holiday} has the lowest correlation with the target variable, suggesting that whether a day is a holiday or not has minimal impact on bike demand.

\subsection{Imbalance in the Dataset}
\label{headings}
Upon analyzing the target variable \textit{increase\_stock}, we found that there is 1312 instances of class 0 (low bike demand) and 288 instances of class 1 (high bike demand). This indicates a significant class imbalance in the dataset \cite{smlbook}, with class 0 being the majority class.

To address this class imbalance, we will employ the use of Synthetic Minority Over-sampling Technique (SMOTE). SMOTE works by generating synthetic samples for the minority class (class 1 in this case) by interpolating between existing minority class instances. This helps to balance the class distribution and provides the model with more representative samples of the minority class during training. \cite{JMLR:v18:16-365}

The interpolation is done by selecting a minority class instance and finding its k-nearest neighbors. A synthetic sample is then created by randomly selecting one of the neighbors and interpolating between the two instances. This process is repeated until the desired balance between the classes is achieved.

\section{Models and Methods}
\label{headings}
In this experiment, we will compare various classification models to determine which one performs best for predicting whether an increase in bike stock is needed using the provided dataset. The models we will consider includes Logistic Regression, Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN), Random Forest, and Gradient Boosting.

For each model, we will perform hyperparameter tuning using techniques such as Grid Search or Random Search combined with cross-validation to find the optimal set of hyperparameters that yield the best performance on the validation set.

\subsection{Benchmark Model}
As the benchmark model, we will use a naive model that predict each instance using stratified random sampling based on the training set's class distribution. This means that for each instance, the model will randomly assign a class label (0 or 1) based on the proportion of each class in the training data \cite{scikit-learn}. This will provide a baseline accuracy to compare the performance of more sophisticated models.

\subsection{Evaluation Metrics}
To evaluate the performance of each classification model, we will use several metrics including Accuracy, Precision, Recall, and F1-Score. These metrics will provide a comprehensive understanding of how well each model performs in predicting the target variable. \cite{smlbook}

We will also use K-Fold Cross Validation to ensure that our evaluation metrics are robust and not overly dependent on a particular train-test split. 

K-Fold Cross Validation involves dividing the dataset into K subsets, using one of the subsets as the test set and the remaining K-1 subsets as the training set. This process is repeated K times, with each subset used as the test set once. The final evaluation metrics are then averaged over all K iterations to provide a more reliable estimate of model performance. For this experiment, we will use K=10. \cite{smlbook}

\subsection{Logistic Regression}
Logistic Regression is a linear model used for binary classification tasks. It models the probability of the target variable being in a particular class using the logistic function. The model estimates the coefficients for each feature, which represent the impact of each feature on the log-odds of the target variable \cite{smlbook}. 

In Logistic Regression, we use the sigmoid function to map the linear combination of features to a probability value between 0 and 1. With the formulation:
\begin{equation*}
    P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n)}}
    \cite{scikit-learn}
\end{equation*}


Where \( P(Y=1|X) \) is the probability of the target variable being in class 1 given the features \( X \), \( \beta_0 \) is the intercept, and \( \beta_1, \beta_2, ..., \beta_n \) are the coefficients for each feature \( X_1, X_2, ..., X_n \).

The parameters of the model are estimated using Maximum Likelihood Estimation (MLE), which finds the set of coefficients that maximize the likelihood of the observed data given the model.

\subsection{Linear Discriminant Analysis (LDA)}
Linear Discriminant Analysis (LDA) is a classification method that finds a linear combination of features that best separates the classes. \cite{smlbook}.

LDA is derived from the probabilistic model which models the class-conditional distributions of the data P(X|y=k) for each class k \cite{scikit-learn}.  Predictions are made by applying Bayes theorem for each training sample $x \in \mathbb{R}^d$:

\begin{equation*}
P(y=k|x) = \frac{P(x|y=k)P(y=k)}{P(x)} \cite{scikit-learn}
\end{equation*}

Then we select the class with the highest posterior probability. For LDA, P(X|y=k) is modeled as a multivariate Gaussian distribution with density function as follows:

\begin{equation*}
P(x|y=k) = \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(x-\mu_k)^T \Sigma^{-1} (x-\mu_k)\right)
\cite{scikit-learn}
\end{equation*}

where $\mu_k$ is the mean vector of class k, and $\Sigma$ is the shared covariance matrix across all classes, and d is the number of features.

In LDA, we assume that the covariance matrices of all classes are equal, i.e., $\Sigma_k = \Sigma$ for all k. This reduces the log posterior to:

\begin{equation*}
\log P(y=k|x) = -\frac{1}{2}(x-\mu_k)^T \Sigma^{-1} (x-\mu_k) + \log P(y=k) + Constant
\cite{scikit-learn}
\end{equation*}

which can be simplified to:
\begin{equation*}
\log P(y=k|x) = w_k^T x + w_{k0} + Constant
\cite{scikit-learn}
\end{equation*}

where \( w_k = \Sigma^{-1} \mu_k \) and \( w_{k0} = -\frac{1}{2} \mu_k^T \Sigma^{-1} \mu_k + \log P(y=k) \). \cite{scikit-learn}

\subsection{K-Nearest Neighbors (KNN)}
K-Nearest Neighbors (KNN) is a non-parametric classification method that classifies new instances based on the majority class of their K nearest neighbors in the feature space. The distance metric used to determine the nearest neighbors can be Euclidean distance, Manhattan distance, or other distance measures. \cite{scikit-learn}

KNN algorithm are usually used for unsupervised learning tasks such as clustering. However, it can also be adapted for supervised learning tasks by using the labels of the nearest neighbors to make predictions. 

For Supervised learning tasks, KNN works using these following steps:
\begin{itemize}
    \item Choose the number of neighbors K.
    \item For each new instance to be classified, calculate the distance between the new instance and all instances in the training dataset.
    \item Identify the K nearest neighbors based on the calculated distances.
    \item Determine the majority class among the K nearest neighbors.
    \item Assign the majority class as the predicted class for the new instance.
\end{itemize}

For the distance metric, we will use Manhattan distance, which is defined as:
\begin{equation*}
    d(p, q) = \sum_{i=1}^{n} |p_i - q_i|
    \cite{scikit-learn}
\end{equation*}
where \( p \) and \( q \) are two instances in the feature space, and \( n \) is the number of features.


\subsection{Random Forest}
Random Forest is an ensemble learning method that consists of multiple decision trees. Each tree is trained on a random subset of the training data and a random subset of features. The final prediction is made by aggregating the predictions from all trees. The method to aggregate the results in this experiment will use majority voting. \cite{scikit-learn}

Decision trees in principle work by recursively splitting the data based on feature values to create branches that lead to leaf nodes representing class labels. The splits are chosen based on the feature that maximizes the information gain or minimizes the impurity at each node. For the metric to measure impurity, we will use Entropy, which is defined as:
\begin{equation*}
    H(X) = -\sum_{i=1}^{c} p_i \log_2(p_i) \cite{scikit-learn}
\end{equation*}
where \( p_i \) is the proportion of instances belonging to class \( i \) in the node, and \( c \) is the number of classes.

Decision trees can be prone to overfitting, especially when they are deep and complex. To mitigate this, we can use Random Forest.

Random Forest Algorithm, works using these following steps:
\begin{itemize}
    \item For each tree in the forest:
    \begin{itemize}
        \item Randomly sample the training data with replacement (bootstrap sampling).
        \item Randomly select a subset of features to consider for splitting at each node.
        \item Train a decision tree on the sampled data using the selected features.
    \end{itemize}
    \item For making predictions:
    \begin{itemize}
        \item For each new instance, pass it through each tree in the forest to obtain the predicted class.
        \item Aggregate the predictions from all trees using majority voting to determine the final predicted class.
    \end{itemize}
\end{itemize}

Due to the randomness introduced in the training process, Random Forests are less prone to overfitting compared to individual decision trees and often achieve better generalization performance. \cite{scikit-learn}

\subsection{Gradient Boosting}
Gradient Boosting is an ensemble learning method that builds a series of weak learners in a sequential manner. Each weak learner is trained to correct the errors made by the previous learners. The final prediction is made by combining the predictions from all weak learners. \cite{scikit-learn}

Gradient Boosting Algorithm works using these following steps:
\begin{itemize}
    \item Initialize the model with a constant value, typically the mean of the target variable.
    \item For each iteration \( m = 1 \) to \( M \):
    \begin{itemize}
        \item Compute the pseudo-residuals, which are the negative gradients of the loss function with respect to the current model's predictions.
        \item Train a weak learner (e.g., decision tree, logistic regression) on the pseudo-residuals.
        \item Compute the optimal step size (learning rate) for the weak learner.
        \item Update the model by adding the weighted predictions of the weak learner to the current model.
    \end{itemize}
    \item For making predictions:
    \begin{itemize}
        \item For each new instance, pass it through all weak learners and sum their weighted predictions to obtain the final predicted value.
    \end{itemize}
\end{itemize} 

Since the problem we're working on is a binary classification task, we will use logistic loss as the loss function for Gradient Boosting. The logistic loss is defined as:
\begin{equation*}
    L(y, \hat{y}) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
    \cite{scikit-learn}
\end{equation*}
where \( y_i \) is the true label, \( \hat{y}_i \) is the predicted probability, and \( N \) is the number of instances. For the weak learners, we will use decision trees with a maximum depth of 5.

\subsection{Hyperparameter Tuning}
For each classification model, we will perform hyperparameter tuning using Grid Search combined with 10-Fold Cross Validation to find the optimal set of hyperparameters that yield the best performance on the validation set. The hyperparameters to be tuned for each model are as follows:

Grid Search works by exhaustively searching through a specified subset of hyperparameters for each model. For each combination of hyperparameters, the model is trained and evaluated using cross-validation. The combination that yields the best average performance across the folds is selected as the optimal set of hyperparameters. \cite{smlbook}

\section{Experiment and Results}
\label{headings}
After performing the experiments using the described models and methods. We obtained the results as shown in Table~\ref{results-table}.

\begin{table}[!ht]
  \caption{Results of Classification Models (rounded to 4 decimal places)}
  \label{results-table}
  \centering
\begin{tabular}{ p{3cm} p{2cm} p{2cm} p{2cm} p{2cm} }
    \textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
    \hline
    Random Forest & 0.9037  & 0.9065  & 0.9037  & 0.9043	  \\
    Gradient Boosting & 0.8994  & 0.9015  & 0.8994  & 0.8999  \\
    Logistic Regression & 0.8100  & 0.8696  & 0.8100  & 0.8271 \\
    LDA & 0.7956  & 0.8676  & 0.7956  & 0.8155 \\
    K-Nearest Neighbors & 0.7675  & 0.8233  & 0.7675  & 0.7863  \\
    Benchmark Model  & 0.4781 & 0.6889 & 0.4781 & 0.5375\\
\end{tabular}
\end{table}

Using Grid Search with 10-Fold Cross Validation, we found the optimal hyperparameters for each model is as follows:
\begin{itemize}
    \item \textbf{Logistic Regression}: Regularization strength \( C = 1.0 \), Solver type using Liblinear, and Penalty type using Ridge Regularization (L2).
    \item \textbf{LDA}: Solver Type using SVD (Singular Value Decomposition)
    \item \textbf{K-Nearest Neighbors}: Number of neighbors \( K = 3 \), Distance metric using Manhattan distance, and Weighting type using the inverse of their distance.
    \item \textbf{Random Forest}: Number of trees \( n\_estimators = 250 \), Maximum depth of each tree \( max\_depth = 15 \), Minimum samples per leaf \( min\_samples\_leaf = 1 \), Minimum samples per split \( min\_samples\_split = 2 \), and Criterion using Entropy.
    \item \textbf{Gradient Boosting}: Number of estimators \( n\_estimators = 100 \), Learning rate = 0.1, Maximum Depth for each estimator = 10, and Subsample = 0.6
\end{itemize}

Based on the results, we can see that the more complex models such as Random Forest and Gradient Boosting outperformed the simpler models like Logistic Regression, LDA, and KNN. 

Random Forest achieved an accuracy of 90.37\%, indicating that it correctly classified a high percentage of instances in the dataset. The F1-Score of 90.43\% also suggests that the model has a good balance between precision and recall, suggesting that it is effective in identifying both positive and negative instances. Gradient Boosting also performed comparably well, achieving an accuracy and F1-Score of 89.94\% and 89.99\% respectively, which is slightly lower than Random Forest but still significantly better than the other models.

If we compare the simpler models such as Logistic Regression, LDA, and KNN, we can see that they achieved lower accuracy and F1-scores. Logistic Regression achieved an accuracy of 81.00\%, LDA achieved 79.56\%, and KNN achieved 76.75\%. This indicates that these models may not be as effective in capturing the complex relationships in the dataset compared to the ensemble methods.

Due to it's superior performance, for production deployment, we recommend using either the Random Forest or Gradient Boosting model for predicting whether an increase in bike stock is needed.

\section{Conclusion}
\label{headings}

Based on the analysis and experiments conducted in this project, we can conclude that the Random Forest is the most effective model for predicting whether an increase in bike stock is needed in Washington D.C. The model achieved the highest accuracy, recall, precision, and F1-score among all the models evaluated.

\medskip
\newpage
\bibliography{ref}

% \newpage
% \appendix
% \section{Appendix}
% \lstinputlisting[language=python]{Jupyter_as_Script.py}

\includepdf[pages=-]{Experiment.pdf}

\end{document}